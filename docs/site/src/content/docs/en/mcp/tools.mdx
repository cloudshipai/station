---
title: MCP Tools Reference
description: Complete reference for all 41 Station MCP tools
---

# MCP Tools Reference

Station provides 41 MCP tools for complete agent management, execution, evaluation, and infrastructure control. All tools are available through your AI assistant (Claude, Cursor, OpenCode, etc.).

## Tool Categories

| Category | Tools | Purpose |
|----------|-------|---------|
| [Agent Management](#agent-management) | 11 | Create, configure, and manage agents |
| [Agent Execution](#agent-execution) | 4 | Run agents and inspect results |
| [Evaluation & Testing](#evaluation--testing) | 7 | Test and benchmark agents |
| [Reports & Analytics](#reports--analytics) | 4 | Performance reporting |
| [Environment Management](#environment-management) | 3 | Manage environments |
| [MCP Server Management](#mcp-server-management) | 5 | Configure MCP servers |
| [Tool Discovery](#tool-discovery) | 2 | Find available tools |
| [Scheduling](#scheduling) | 3 | Automate agent runs |
| [Bundles](#bundles) | 1 | Package agents |
| [Faker System](#faker-system) | 1 | Mock data generation |

---

## Agent Management

### `create_agent`
Create a new agent with prompts, tools, and configuration.

```
"Create a cost-analyzer agent that uses AWS tools to analyze spending"
```

**Parameters:**
- `name` (required) - Agent name
- `description` (required) - What the agent does
- `prompt` (required) - System prompt
- `environment_id` - Target environment
- `max_steps` - Maximum execution steps (default: 5)
- `tool_names` - List of tools to assign
- `sandbox` - Sandbox configuration (python/node/bash)
- `output_schema` - JSON schema for structured output

### `update_agent`
Modify an existing agent's configuration.

```
"Update cost-analyzer to use max_steps 10"
```

### `update_agent_prompt`
Update only the agent's system prompt.

```
"Update the prompt for incident-coordinator to be more concise"
```

### `delete_agent`
Remove an agent permanently.

```
"Delete the old-analyzer agent"
```

### `list_agents`
List all agents with optional filters.

```
"List all agents in the production environment"
```

**Parameters:**
- `environment_id` - Filter by environment
- `enabled_only` - Show only enabled agents
- `limit` - Max results (default: 50)
- `offset` - Pagination offset

### `get_agent_details`
Get complete configuration for a specific agent.

```
"Show me details for the incident-coordinator agent"
```

### `get_agent_schema`
Get the input schema for an agent's dotprompt template.

```
"What variables does cost-analyzer accept?"
```

### `add_tool`
Assign an MCP tool to an agent.

```
"Add the __aws_cost_explorer tool to cost-analyzer"
```

### `remove_tool`
Remove a tool from an agent.

```
"Remove __deprecated_tool from my-agent"
```

### `add_agent_as_tool`
Create multi-agent hierarchies by adding an agent as a callable tool.

```
"Add logs-investigator as a tool for incident-coordinator"
```

### `remove_agent_as_tool`
Break an agent hierarchy link.

```
"Remove logs-investigator from incident-coordinator's tools"
```

---

## Agent Execution

### `call_agent`
Execute an agent with a specific task.

```
"Run cost-analyzer with task: Analyze last week's AWS spending"
```

**Parameters:**
- `agent_id` (required) - Agent to execute
- `task` (required) - Task/prompt to run
- `variables` - Input variables for dotprompt
- `async` - Run asynchronously (default: false)
- `store_run` - Save to history (default: true)
- `timeout` - Timeout in seconds (default: 300)

### `list_runs`
List agent execution history.

```
"Show me the last 20 runs for cost-analyzer"
```

**Parameters:**
- `agent_id` - Filter by agent
- `status` - Filter by status (success/error/running)
- `limit` - Max results (default: 50)

### `inspect_run`
Get detailed information about a specific run.

```
"Show me details for run 123"
```

**Parameters:**
- `run_id` (required) - Run to inspect
- `verbose` - Include full tool calls (default: true)

### `list_runs_by_model`
Filter runs by AI model.

```
"Show me all runs using gpt-4o-mini"
```

---

## Evaluation & Testing

### `generate_and_test_agent`
Generate test scenarios and run comprehensive agent testing.

```
"Generate 50 test scenarios for incident-coordinator and run them"
```

**Parameters:**
- `agent_id` (required) - Agent to test
- `scenario_count` - Number of scenarios (default: 100)
- `max_concurrent` - Parallel executions (default: 10)
- `variation_strategy` - comprehensive/edge_cases/common

### `batch_execute_agents`
Run multiple agents concurrently for testing.

```
"Run cost-analyzer and security-scanner in parallel with 5 iterations each"
```

**Parameters:**
- `tasks` - JSON array of execution tasks
- `iterations` - Times to run each (default: 1, max: 100)
- `max_concurrent` - Parallel limit (default: 5, max: 20)

### `evaluate_benchmark`
Run LLM-as-judge evaluation on a completed run.

```
"Evaluate run 123 using the benchmark system"
```

### `evaluate_dataset`
Evaluate an entire dataset of agent runs.

```
"Evaluate the dataset at /path/to/dataset"
```

### `export_dataset`
Export runs for external analysis.

```
"Export the last 100 runs to Genkit format"
```

**Parameters:**
- `filter_agent_id` - Filter by agent
- `filter_model` - Filter by model
- `limit` - Max runs (default: 100)
- `output_dir` - Output directory (default: ./evals/)

### `list_benchmark_results`
List previous evaluation results.

```
"Show me benchmark results for run 123"
```

### `get_benchmark_status`
Check status of an evaluation task.

```
"What's the status of benchmark task abc123?"
```

---

## Reports & Analytics

### `create_report`
Create a new performance report definition.

```
"Create a weekly report for the SRE team measuring incident response time"
```

**Parameters:**
- `name` (required) - Report name
- `environment_id` (required) - Environment to evaluate
- `team_criteria` (required) - JSON defining success metrics
- `agent_criteria` - Per-agent metrics
- `filter_model` - Filter by AI model

### `generate_report`
Run benchmarks and generate a report.

```
"Generate the SRE team performance report"
```

### `list_reports`
List all report definitions.

```
"Show me all reports for production"
```

### `get_report`
Get details of a specific report.

```
"Show me the latest SRE report results"
```

---

## Environment Management

### `create_environment`
Create a new environment.

```
"Create a staging environment"
```

### `delete_environment`
Delete an environment and all its data.

```
"Delete the old-staging environment"
```

### `list_environments`
List all environments.

```
"What environments do I have?"
```

---

## MCP Server Management

### `add_mcp_server_to_environment`
Add an MCP server configuration.

```
"Add a Datadog MCP server to production"
```

**Parameters:**
- `environment_name` (required)
- `server_name` (required)
- `command` (required) - Server command
- `args` - Command arguments
- `env` - Environment variables
- `description` - Server description

### `update_mcp_server_in_environment`
Update an existing MCP server.

```
"Update the datadog server to use a new API key"
```

### `delete_mcp_server_from_environment`
Remove an MCP server.

```
"Remove the deprecated-server from production"
```

### `list_mcp_servers_for_environment`
List servers in an environment.

```
"What MCP servers are in production?"
```

### `list_mcp_configs`
List all MCP configurations.

```
"Show me all MCP configs across environments"
```

---

## Tool Discovery

### `discover_tools`
Discover tools from MCP server configurations.

```
"Discover what tools are available from the AWS server"
```

**Parameters:**
- `environment_id` - Filter by environment
- `config_id` - Specific MCP config

### `list_tools`
List available tools with search.

```
"List all tools that mention 'cost'"
```

**Parameters:**
- `environment_id` - Filter by environment
- `search` - Search term
- `limit` - Max results (default: 50)

---

## Scheduling

### `set_schedule`
Schedule an agent to run automatically.

```
"Schedule cost-analyzer to run daily at 9 AM"
```

**Parameters:**
- `agent_id` (required)
- `cron_schedule` (required) - 6-field cron expression
- `schedule_variables` - Variables for scheduled runs
- `enabled` - Enable/disable (default: true)

### `get_schedule`
View an agent's schedule.

```
"What's the schedule for cost-analyzer?"
```

### `remove_schedule`
Remove an agent's schedule.

```
"Remove the schedule from cost-analyzer"
```

---

## Bundles

### `create_bundle_from_environment`
Package an environment as a distributable bundle.

```
"Create a bundle from the production environment"
```

**Parameters:**
- `environmentName` (required)
- `outputPath` - Output file path

---

## Faker System

### `faker_create_standalone`
Create an AI-powered mock data server.

```
"Create a prometheus faker that generates Kubernetes metrics"
```

**Parameters:**
- `environment_name` (required)
- `faker_name` (required)
- `description` (required)
- `goal` (required) - AI instruction for data generation
- `tools` - JSON array of tool definitions
- `auto_sync` - Sync to environment (default: true)
- `persist` - Persist to template.json (default: true)

---

## Usage Examples

### Create an Incident Response Team

```
You: Create an incident response team with a coordinator and three specialists

Claude: I'll create the team for you.

[Using create_agent with name="incident-coordinator"...]
✅ Created incident_coordinator

[Using create_agent with name="logs-investigator"...]
✅ Created logs_investigator

[Using add_agent_as_tool...]
✅ Added logs_investigator as tool for incident_coordinator

[Continues for all specialists...]

Your incident response team is ready!
```

### Run a Cost Analysis

```
You: Analyze yesterday's AWS costs

Claude: I'll run the cost analyzer.

[Using call_agent with agent_id="21", task="Analyze yesterday's costs"...]

Results:
- Total spend: $1,247.32
- Top service: EC2 ($580)
- 15% increase from last week
- Anomaly detected: Lambda costs up 40%
```

### Generate Performance Report

```
You: How is my SRE team performing?

Claude: [Using generate_report with report_id="sre-team"...]

Team Performance: 7.5/10
- Incident response: 8.5/10
- Tool utilization: 8.0/10
- Root cause accuracy: 7.5/10
- Communication: 6.5/10
```

## Tool Naming Convention

- Station tools appear with prefix based on your MCP client
- In OpenCode: `opencode-station_create_agent`
- In Claude Desktop: `station-create_agent`
- Tool names from MCP servers use `__` prefix: `__aws_cost_explorer`

## Next Steps

- [Agent Configuration](/station/en/agents/config) - Detailed agent setup
- [Scheduling](/station/en/scheduling) - Automate agent runs
- [Observability](/station/en/observability) - Monitor agent execution
